{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hHQMdtDSHmlLtniyjUHWKeC2U8C1qJGW",
      "authorship_tag": "ABX9TyOdr8oe7G9/vu2qzgWV6gWy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnCimm/Two-Step-Deep-Learning-Approach-for-Denoising-RF-Transmitted-Images-Under-Jamming-/blob/main/sigmfToTXT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffXecSQIOGoV",
        "outputId": "3448ddba-2d96-4c8f-ec6a-7856c1fa4b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sigmf\n",
            "  Downloading SigMF-1.2.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sigmf) (1.26.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from sigmf) (4.23.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sigmf) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sigmf) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sigmf) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->sigmf) (0.22.3)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->sigmf) (4.12.2)\n",
            "Downloading SigMF-1.2.6-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: sigmf\n",
            "Successfully installed sigmf-1.2.6\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "!pip install sigmf\n",
        "from sigmf import SigMFFile, sigmffile\n",
        "\n",
        "contact_email = 'aia-rf@mit.edu'\n",
        "\n",
        "\n",
        "# adapted from \"Use Case\" in gnuradio/SigMF repository (https://github.com/gnuradio/SigMF)\n",
        "\n",
        "def read_sigmf_file(filename=f'sample', folderpath=None):\n",
        "\n",
        "    # Load a dataset\n",
        "    full_filename = filename\n",
        "    if folderpath is not None:\n",
        "        full_filename = os.path.join(folderpath, filename)\n",
        "\n",
        "    meta = sigmffile.fromfile(full_filename)\n",
        "\n",
        "    # Get some metadata and all annotations\n",
        "    sample_rate = meta.get_global_field(SigMFFile.SAMPLE_RATE_KEY)\n",
        "    sample_count = meta.sample_count\n",
        "    signal_duration = sample_count / sample_rate\n",
        "\n",
        "    data = meta.read_samples(0, meta.sample_count)\n",
        "    return data, meta\n",
        "\n",
        "#data,meta = read_sigmf_file('/content/CommSignal2_train_frame_0000.sigmf-data')\n",
        "#os.makedirs('/content/dataset')\n",
        "#fullName = os.path.join('/content/dataset','CommSignal2_0000')\n",
        "#print(data)\n",
        "#data.tofile('/content/dataset/CommSignal2_0000',' ')\n",
        "\n",
        "\n",
        "def write_sigmf_file(data, filename=f'sample', folderpath=None, fs=1, fc=0, description=''):\n",
        "    assert data.dtype == 'complex64'\n",
        "\n",
        "    full_filename = filename\n",
        "    if folderpath is not None:\n",
        "        if not os.path.exists(folderpath):\n",
        "            os.makedirs(folderpath)\n",
        "        full_filename = os.path.join(folderpath, filename)\n",
        "\n",
        "    # write those samples to file in cf32_le\n",
        "    data.tofile(f\"{full_filename}.sigmf-data\")\n",
        "\n",
        "    # create the metadata\n",
        "    meta = SigMFFile(\n",
        "        data_file=f\"{full_filename}.sigmf-data\", # extension is optional\n",
        "        global_info = {\n",
        "            SigMFFile.DATATYPE_KEY: 'cf32_le',\n",
        "            SigMFFile.SAMPLE_RATE_KEY: fs,\n",
        "            SigMFFile.AUTHOR_KEY: contact_email,\n",
        "            SigMFFile.DESCRIPTION_KEY: description,\n",
        "            SigMFFile.VERSION_KEY: sigmf.__version__,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create a capture key at time index 0\n",
        "    meta.add_capture(0, metadata={\n",
        "        SigMFFile.FREQUENCY_KEY: fc,\n",
        "        SigMFFile.DATETIME_KEY: dt.datetime.utcnow().isoformat()+'Z',\n",
        "    })\n",
        "\n",
        "    # check for mistakes & write to disk\n",
        "    assert meta.validate()\n",
        "    meta.tofile(f\"{full_filename}.sigmf-meta\") # extension is optional\n",
        "\n",
        "    return data, meta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def load_dataset_sample(idx, dataset_type, sig_type):\n",
        "    foldername = os.path.join('dataset',dataset_type,sig_type)\n",
        "    filename = f'{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    # Special handling for \"Separation\" validation and test set; only using Comm2 vs [sig_type] for this iteration\n",
        "    if 'sep_' in dataset_type:\n",
        "        filename = f'CommSignal2_vs_{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    data, meta = read_sigmf_file(filename=filename, folderpath=foldername)\n",
        "    return data, meta\n",
        "\n",
        "def load_dataset_sample_components(idx, dataset_type, sig_type):\n",
        "    assert 'train' in dataset_type or 'val' in dataset_type or 'test' in dataset_type, f'Invalid dataset type requested for obtaining components: {dataset_type}'\n",
        "\n",
        "    soi_name = 'Comm2' if 'sep_' in dataset_type else 'QPSK'\n",
        "    foldername1 = os.path.join('dataset',dataset_type,'Components', sig_type, soi_name)\n",
        "    filename1 = f'{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    # Special handling for \"Separation\" validation and test set; only using Comm2 vs [sig_type] for this iteration\n",
        "    if 'sep_' in dataset_type:\n",
        "        filename1 = f'CommSignal2_vs_{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    data1, meta1 = read_sigmf_file(filename=filename1, folderpath=foldername1)\n",
        "\n",
        "    foldername2 = os.path.join('dataset',dataset_type,'Components', sig_type, 'Interference')\n",
        "    filename2 = f'{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    # Special handling for \"Separation\" validation and test set; only using Comm2 vs [sig_type] for this iteration\n",
        "    if 'sep_' in dataset_type:\n",
        "        filename2 = f'CommSignal2_vs_{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    data2, meta2 = read_sigmf_file(filename=filename1, folderpath=foldername2)\n",
        "\n",
        "    return data1, meta1, data2, meta2\n",
        "\n",
        "def load_dataset_sample_demod_groundtruth(idx, dataset_type, sig_type):\n",
        "    assert 'train' in dataset_type or 'val' in dataset_type or 'test' in dataset_type, f'Invalid dataset type requested for obtaining components: {dataset_type}'\n",
        "    assert 'demod_' in dataset_type, f'Invalid dataset type requested for obtaining components: {dataset_type}'\n",
        "\n",
        "    foldername = os.path.join('dataset',dataset_type,'Components',sig_type,'QPSK')\n",
        "    filename = f'{sig_type}_{dataset_type}_{idx:04d}'\n",
        "    data, meta = read_sigmf_file(filename=filename, folderpath=foldername)\n",
        "\n",
        "    msg_folder = os.path.join('dataset',dataset_type,'QPSK_Bits',sig_type)\n",
        "    msg_filename = f'{sig_type}_{dataset_type}_QPSK_bits_{idx:04d}'\n",
        "    msg_bits, ground_truth_info = pickle.load(open(os.path.join(msg_folder,f'{msg_filename}.pkl'),'rb'))\n",
        "    return data, meta, msg_bits, ground_truth_info\n",
        "\n",
        "\n",
        "def demod_check_ber(bit_est, idx, dataset_type, sig_type):\n",
        "    assert 'demod_' in dataset_type, f'Invalid dataset type requested for obtaining components: {dataset_type}'\n",
        "\n",
        "    msg_folder = os.path.join('dataset',dataset_type,'QPSK_Bits',sig_type)\n",
        "    msg_filename = f'{sig_type}_{dataset_type}_QPSK_bits_{idx:04d}'\n",
        "    bit_true, _ = pickle.load(open(os.path.join(msg_folder,f'{msg_filename}.pkl'),'rb'))\n",
        "    if len(bit_est) != len(bit_true):\n",
        "        warnings.warn(f'Mismatch in estimated bit message length ({len(bit_est)}) and true bit message length ({len(bit_true)})')\n",
        "        msg_len = min(len(bit_true), len(bit_est))\n",
        "        bit_true = bit_true[:msg_len]\n",
        "        bit_est = bit_est[:msg_len]\n",
        "    ber = np.sum(np.abs(bit_est-bit_true))/len(bit_true)\n",
        "    return ber\n"
      ],
      "metadata": {
        "id": "whBRCuvWPC9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sinr = lambda s, i: 10*np.log10(np.mean(np.abs(s)**2)/np.mean(np.abs(i)**2))\n",
        "\n",
        "# sig_type = \"EMISignal1\"\n",
        "# sig_type = \"CommSignal2\"\n",
        "sig_type = \"CommSignal3\"\n",
        "\n",
        "num_train_frame = {\"EMISignal1\": 580, \"CommSignal2\": 150, \"CommSignal3\": 139}\n",
        "# num_all_frame = {\"EMISignal1\": 580, \"CommSignal2\": 150, \"CommSignal3\": 189}\n",
        "sig_dataset = []\n",
        "for ii in range(num_train_frame[sig_type]):\n",
        "    filename = f'{sig_type}_{\"train_frame\"}_{ii:04d}_{\".txt\"}'\n",
        "    data,meta = load_dataset_sample(ii, \"train_frame\", sig_type)\n",
        "    sig_dataset.append(data)\n",
        "\n",
        "    fullName = os.path.join('/content/drive/MyDrive/CommSig3',filename)\n",
        "    data.tofile(fullName,' ')\n",
        "sig_dataset = np.array(sig_dataset)\n",
        "#data,meta = read_sigmf_file('/content/CommSignal2_train_frame_0000.sigmf-data')\n",
        "\n"
      ],
      "metadata": {
        "id": "VqgRDGMCOZn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}